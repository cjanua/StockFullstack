#docker-compose.dev.yaml

services:
  portfolio-service:
    build:
      target: dev
    # Mount source for live-reload inside the container
    volumes:
      - ./backend/alpaca:/app/backend/alpaca
      - alpaca_venv:/opt/venv
    environment:
      # Improve file watching on mounted volumes (use polling)
      WATCHFILES_FORCE_POLLING: "1"

  dashboard:
    build:
      target: dev
    volumes:
      - ./dashboard:/app
      - dashboard_node_modules:/app/node_modules
    command: ["npm", "run", "dev"]
    environment:
      - NODE_ENV=development
      - NEXT_TELEMETRY_DISABLED=1
      - CHOKIDAR_USEPOLLING=true
      - CHOKIDAR_INTERVAL=1000
      - NEXT_PUBLIC_PORTFOLIO_SERVICE_URL=http://portfolio-service-py-stockfullstack:8001

  ai-training:
    build:
      context: .  # Build from project root to include stock_fullstack package
      dockerfile: ai/Dockerfile
    container_name: ai-training-stockfullstack
    restart: unless-stopped
    environment:
      - LD_LIBRARY_PATH=/usr/lib/wsl/lib:$LD_LIBRARY_PATH
    volumes:
      - .:/workspace  # Mount the entire project directory
      - /usr/lib/wsl/lib/libdxcore.so:/usr/lib/libdxcore.so:ro  # WSL-specific library
      - /opt/rocm/lib/libhsa-runtime64.so.1:/opt/rocm/lib/libhsa-runtime64.so.1:ro  # WSL-compatible HSA runtime
      - /usr/lib/wsl:/usr/lib/wsl  # Full WSL libraries for fallback
    devices:
      - /dev/dxg:/dev/dxg
    cap_add:
      - SYS_PTRACE
    security_opt:
      - seccomp=unconfined
    group_add:
      - video
    ipc: host
    shm_size: 16g
    networks:
      - stock_network

volumes:
  dashboard_node_modules:
  alpaca_venv:
  torch-lib: